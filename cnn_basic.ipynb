{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils, print_summary\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "# Image dimensions\n",
    "img_width, img_height = 150, 150 \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(p, input_shape=(32, 32, 3)):\n",
    "    # Initialising the CNN\n",
    "    model = Sequential()\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution  followed by Pooling Layer \n",
    "    # increasing the number of filters as we have pooled out features reduced features. we can afford to apply 64 filters.\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully connection ANN\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p/2))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "        # Compiling the CNN\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    metrics=['accuracy']\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = \"cnn_v0.h5\"\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    #checkpoint2 = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint1]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(bs=32, epochs=10):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                       shear_range = 0.2, \n",
    "                                       zoom_range = 0.2, \n",
    "                                       horizontal_flip = True)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    " \n",
    "    training_set = train_datagen.flow_from_directory('C:/Users/chall/Desktop/dataset-train',\n",
    "                                                 target_size = (img_width, img_height),\n",
    "                                                 batch_size = bs,\n",
    "                                                 class_mode = \"categorical\"\n",
    "                                                    )\n",
    "                                                 \n",
    "    test_set = test_datagen.flow_from_directory('C:/Users/chall/Desktop/dataset-test',\n",
    "                                            target_size = (img_width, img_height),\n",
    "                                            batch_size = bs,\n",
    "                                            class_mode = 'categorical')\n",
    "                                            \n",
    "    model = create_model(p=0.6, input_shape=(img_width, img_height, 3))                                  \n",
    "    model.fit_generator(training_set,\n",
    "                         steps_per_epoch=1000/bs,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/bs\n",
    "                    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1915 images belonging to 6 classes.\n",
      "Found 612 images belonging to 6 classes.\n",
      "Epoch 1/10\n",
      "32/31 [==============================] - 67s 2s/step - loss: 0.5268 - acc: 0.7848 - val_loss: 0.4487 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "32/31 [==============================] - 63s 2s/step - loss: 0.4688 - acc: 0.8301 - val_loss: 0.4544 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "32/31 [==============================] - 61s 2s/step - loss: 0.4597 - acc: 0.8332 - val_loss: 0.4483 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "32/31 [==============================] - 63s 2s/step - loss: 0.4536 - acc: 0.8330 - val_loss: 0.4561 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "32/31 [==============================] - 62s 2s/step - loss: 0.4571 - acc: 0.8333 - val_loss: 0.4545 - val_acc: 0.8333\n",
      "Epoch 6/10\n",
      "32/31 [==============================] - 63s 2s/step - loss: 0.4497 - acc: 0.8333 - val_loss: 0.4476 - val_acc: 0.8333\n",
      "Epoch 7/10\n",
      "32/31 [==============================] - 61s 2s/step - loss: 0.4475 - acc: 0.8333 - val_loss: 0.4594 - val_acc: 0.8333\n",
      "Epoch 8/10\n",
      "32/31 [==============================] - 62s 2s/step - loss: 0.4468 - acc: 0.8333 - val_loss: 0.4524 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "32/31 [==============================] - 63s 2s/step - loss: 0.4482 - acc: 0.8333 - val_loss: 0.4567 - val_acc: 0.8333\n",
      "Epoch 10/10\n",
      "32/31 [==============================] - 62s 2s/step - loss: 0.4428 - acc: 0.8333 - val_loss: 0.4503 - val_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "classifier = run_training(bs=32, epochs=10)#100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('garbage1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('garbage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "model1 = load_model('garbage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
